{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Paths:\n",
      "/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python310.zip\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python3.10\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python3.10/lib-dynload\n",
      "\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python3.10/site-packages\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python3.10/site-packages/setuptools/_vendor\n",
      "/tmp/tmp9wrqhw11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dinov2:xFormers not available\n",
      "WARNING:dinov2:xFormers not available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.slam_helpers import transform_to_frame,transformed_params2depthplussilhouette,transformed_params2rendervar,transformed_GRNparams2rendervar,transformed_GRNparams2depthplussilhouette\n",
    "from diff_gaussian_rasterization import GaussianRasterizer as Renderer\n",
    "from scripts.main_SurgeSplat import deform_gaussians, setup_camera\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics = torch.tensor([[199.6883,   0.0000, 166.3290],\n",
    "        [  0.0000, 249.4753, 170.4058],\n",
    "        [  0.0000,   0.0000,   1.0000]], device='cuda:0')\n",
    "w2c = torch.tensor([[ 1.0000e+00,  6.5711e-11,  2.3283e-10,  0.0000e+00],\n",
    "        [-3.1832e-11,  1.0000e+00, -7.4115e-21,  0.0000e+00],\n",
    "        [-9.2644e-22,  2.9104e-11,  1.0000e+00,  0.0000e+00],\n",
    "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
    "\n",
    "cam = setup_camera(336,336, intrinsics.cpu().numpy(), w2c.detach().cpu().numpy(), use_simplification=True,bg = [1,1,1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 1\n",
    "all_params = np.load(f'/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/experiments_backup/RARP simple_3/simple_3/params.npz',allow_pickle=True)\n",
    "params={}\n",
    "for key in all_params.keys():\n",
    "    try:\n",
    "        params[key] = torch.tensor(all_params[key]).cuda()\n",
    "    except:\n",
    "        params[key] = [torch.tensor(all_params[key][i]).cuda() for i in range(all_params[key].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     all_params = {k: torch.tensor(all_params[k]).cuda().float() for k in all_params.keys()}\n",
    "\n",
    "\n",
    "#     keys = [k for k in all_params.keys() if\n",
    "#             k not in ['org_width', 'org_height', 'w2c', 'intrinsics', \n",
    "#                     'gt_w2c_all_frames', 'cam_unnorm_rots',\n",
    "#                     'cam_trans', 'keyframe_time_indices']]\n",
    "\n",
    "#     params = all_params\n",
    "#     for k in keys:\n",
    "#         if not isinstance(all_params[k], torch.Tensor):\n",
    "#             params[k] = torch.tensor(all_params[k]).cuda().float()\n",
    "#         else:\n",
    "#             params[k] = all_params[k].cuda().float()\n",
    "# except:\n",
    "#     # keys = [k for k in all_params.keys() if\n",
    "#     #         k not in ['org_width', 'org_height', 'w2c', 'intrinsics', \n",
    "#     #                 'gt_w2c_all_frames', 'cam_unnorm_rots',\n",
    "#     #                 'cam_trans', 'keyframe_time_indices']]\n",
    "#     params={}\n",
    "#     for key in all_params.keys():\n",
    "#         try:\n",
    "#             params[key] = torch.tensor(all_params[key]).cuda()\n",
    "#         except:\n",
    "#             params[key] = [torch.tensor(all_params[key][i]).cuda() for i in range(all_params[key].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114920, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['means3D'][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(91.0990, device='cuda:0')\n",
      "torch.Size([112733, 3])\n",
      "tensor(91.0990, device='cuda:0')\n",
      "torch.Size([112733, 3])\n",
      "tensor(91.0990, device='cuda:0')\n",
      "torch.Size([112749, 3])\n",
      "tensor(91.0990, device='cuda:0')\n",
      "torch.Size([112759, 3])\n",
      "tensor(91.0990, device='cuda:0')\n",
      "torch.Size([112769, 3])\n",
      "tensor(91.0027, device='cuda:0')\n",
      "torch.Size([112780, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([112808, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([112822, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([112822, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([112897, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([112951, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([113020, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([113035, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([113047, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([113055, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([113055, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([113068, 3])\n",
      "tensor(90.9985, device='cuda:0')\n",
      "torch.Size([113073, 3])\n",
      "tensor(91.0002, device='cuda:0')\n",
      "torch.Size([113082, 3])\n",
      "tensor(91.0676, device='cuda:0')\n",
      "torch.Size([113102, 3])\n",
      "tensor(91.0619, device='cuda:0')\n",
      "torch.Size([113117, 3])\n",
      "tensor(90.9345, device='cuda:0')\n",
      "torch.Size([113120, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113133, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113133, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113147, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113159, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113173, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113191, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113206, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113226, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113243, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113243, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113269, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113295, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113327, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113343, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113356, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113369, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113377, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113377, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113393, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113420, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113437, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113472, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113508, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113517, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113527, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113527, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113546, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113573, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113588, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113600, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113623, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113637, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113653, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113653, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113667, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113676, 3])\n",
      "tensor(90.8770, device='cuda:0')\n",
      "torch.Size([113682, 3])\n",
      "tensor(90.8959, device='cuda:0')\n",
      "torch.Size([113690, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113707, 3])\n",
      "tensor(90.8752, device='cuda:0')\n",
      "torch.Size([113721, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113740, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113740, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113774, 3])\n",
      "tensor(90.9794, device='cuda:0')\n",
      "torch.Size([113796, 3])\n",
      "tensor(90.8679, device='cuda:0')\n",
      "torch.Size([113821, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113840, 3])\n",
      "tensor(90.9502, device='cuda:0')\n",
      "torch.Size([113858, 3])\n",
      "tensor(90.9918, device='cuda:0')\n",
      "torch.Size([113876, 3])\n",
      "tensor(90.9957, device='cuda:0')\n",
      "torch.Size([113899, 3])\n",
      "tensor(90.9957, device='cuda:0')\n",
      "torch.Size([113899, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([113938, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([114008, 3])\n",
      "tensor(90.9265, device='cuda:0')\n",
      "torch.Size([114076, 3])\n",
      "tensor(90.8808, device='cuda:0')\n",
      "torch.Size([114210, 3])\n",
      "tensor(90.9573, device='cuda:0')\n",
      "torch.Size([114287, 3])\n",
      "tensor(90.9916, device='cuda:0')\n",
      "torch.Size([114307, 3])\n",
      "tensor(91.0082, device='cuda:0')\n",
      "torch.Size([114335, 3])\n",
      "tensor(91.0082, device='cuda:0')\n",
      "torch.Size([114335, 3])\n",
      "tensor(90.9416, device='cuda:0')\n",
      "torch.Size([114352, 3])\n",
      "tensor(90.9457, device='cuda:0')\n",
      "torch.Size([114370, 3])\n",
      "tensor(90.8746, device='cuda:0')\n",
      "torch.Size([114391, 3])\n",
      "tensor(90.8886, device='cuda:0')\n",
      "torch.Size([114404, 3])\n",
      "tensor(90.9387, device='cuda:0')\n",
      "torch.Size([114419, 3])\n",
      "tensor(90.9001, device='cuda:0')\n",
      "torch.Size([114433, 3])\n",
      "tensor(90.9068, device='cuda:0')\n",
      "torch.Size([114443, 3])\n",
      "tensor(90.9068, device='cuda:0')\n",
      "torch.Size([114443, 3])\n",
      "tensor(90.8857, device='cuda:0')\n",
      "torch.Size([114459, 3])\n",
      "tensor(90.8767, device='cuda:0')\n",
      "torch.Size([114469, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([114482, 3])\n",
      "tensor(90.8598, device='cuda:0')\n",
      "torch.Size([114492, 3])\n",
      "tensor(90.8966, device='cuda:0')\n",
      "torch.Size([114503, 3])\n",
      "tensor(90.9342, device='cuda:0')\n",
      "torch.Size([114512, 3])\n",
      "tensor(91.0928, device='cuda:0')\n",
      "torch.Size([114524, 3])\n",
      "tensor(91.0928, device='cuda:0')\n",
      "torch.Size([114524, 3])\n",
      "tensor(91.0944, device='cuda:0')\n",
      "torch.Size([114532, 3])\n",
      "tensor(91.1690, device='cuda:0')\n",
      "torch.Size([114542, 3])\n",
      "tensor(91.1647, device='cuda:0')\n",
      "torch.Size([114544, 3])\n",
      "tensor(91.1249, device='cuda:0')\n",
      "torch.Size([114555, 3])\n",
      "tensor(91.1625, device='cuda:0')\n",
      "torch.Size([114569, 3])\n",
      "tensor(91.1111, device='cuda:0')\n",
      "torch.Size([114575, 3])\n",
      "tensor(91.0536, device='cuda:0')\n",
      "torch.Size([114582, 3])\n",
      "tensor(91.0536, device='cuda:0')\n",
      "torch.Size([114582, 3])\n",
      "tensor(91.0947, device='cuda:0')\n",
      "torch.Size([114592, 3])\n",
      "tensor(91.1388, device='cuda:0')\n",
      "torch.Size([114605, 3])\n",
      "tensor(91.2195, device='cuda:0')\n",
      "torch.Size([114616, 3])\n",
      "tensor(91.1553, device='cuda:0')\n",
      "torch.Size([114626, 3])\n",
      "tensor(91.1591, device='cuda:0')\n",
      "torch.Size([114633, 3])\n",
      "tensor(91.1410, device='cuda:0')\n",
      "torch.Size([114642, 3])\n",
      "tensor(91.1978, device='cuda:0')\n",
      "torch.Size([114645, 3])\n",
      "tensor(91.1978, device='cuda:0')\n",
      "torch.Size([114645, 3])\n",
      "tensor(91.2400, device='cuda:0')\n",
      "torch.Size([114653, 3])\n",
      "tensor(91.2206, device='cuda:0')\n",
      "torch.Size([114657, 3])\n",
      "tensor(91.2079, device='cuda:0')\n",
      "torch.Size([114663, 3])\n",
      "tensor(91.2419, device='cuda:0')\n",
      "torch.Size([114676, 3])\n",
      "tensor(91.3021, device='cuda:0')\n",
      "torch.Size([114680, 3])\n",
      "tensor(91.3965, device='cuda:0')\n",
      "torch.Size([114685, 3])\n",
      "tensor(90.9509, device='cuda:0')\n",
      "torch.Size([114687, 3])\n",
      "tensor(90.9509, device='cuda:0')\n",
      "torch.Size([114687, 3])\n",
      "tensor(90.9449, device='cuda:0')\n",
      "torch.Size([114691, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114700, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114704, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114712, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114721, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114730, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114732, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114732, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114737, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114745, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114752, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114754, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114757, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114764, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114771, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114771, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114776, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114782, 3])\n",
      "tensor(91.0262, device='cuda:0')\n",
      "torch.Size([114793, 3])\n",
      "tensor(91.1288, device='cuda:0')\n",
      "torch.Size([114806, 3])\n",
      "tensor(91.3386, device='cuda:0')\n",
      "torch.Size([114814, 3])\n",
      "tensor(90.8943, device='cuda:0')\n",
      "torch.Size([114822, 3])\n",
      "tensor(90.9490, device='cuda:0')\n",
      "torch.Size([114830, 3])\n",
      "tensor(90.9490, device='cuda:0')\n",
      "torch.Size([114830, 3])\n",
      "tensor(91.0414, device='cuda:0')\n",
      "torch.Size([114836, 3])\n",
      "tensor(91.1148, device='cuda:0')\n",
      "torch.Size([114845, 3])\n",
      "tensor(91.0609, device='cuda:0')\n",
      "torch.Size([114853, 3])\n",
      "tensor(91.0275, device='cuda:0')\n",
      "torch.Size([114880, 3])\n",
      "tensor(91.0072, device='cuda:0')\n",
      "torch.Size([114883, 3])\n",
      "tensor(90.9564, device='cuda:0')\n",
      "torch.Size([114896, 3])\n",
      "tensor(90.9842, device='cuda:0')\n",
      "torch.Size([114904, 3])\n",
      "tensor(90.9842, device='cuda:0')\n",
      "torch.Size([114904, 3])\n",
      "tensor(90.9936, device='cuda:0')\n",
      "torch.Size([114910, 3])\n",
      "tensor(90.9010, device='cuda:0')\n",
      "torch.Size([114914, 3])\n",
      "tensor(90.9672, device='cuda:0')\n",
      "torch.Size([114920, 3])\n"
     ]
    }
   ],
   "source": [
    "def deform_gaussians(params, time, deform_grad, N=5,deformation_type = 'gaussian'):\n",
    "    \"\"\"\n",
    "    Calculate deformations using the N closest basis functions based on |time - bias|.\n",
    "\n",
    "    Args:\n",
    "        params (dict): Dictionary containing deformation parameters.\n",
    "        time (torch.Tensor): Current time step.\n",
    "        deform_grad (bool): Whether to calculate gradients for deformations.\n",
    "        N (int): Number of closest basis functions to consider.\n",
    "\n",
    "    Returns:\n",
    "        xyz (torch.Tensor): Updated 3D positions.\n",
    "        rots (torch.Tensor): Updated rotations.\n",
    "        scales (torch.Tensor): Updated scales.\n",
    "    \"\"\"\n",
    "    if deformation_type =='gaussian':\n",
    "        if True:\n",
    "            if deform_grad:\n",
    "                weights = params['deform_weights']\n",
    "                stds = params['deform_stds']\n",
    "                biases = params['deform_biases']\n",
    "            else:\n",
    "                weights = params['deform_weights'].detach()\n",
    "                stds = params['deform_stds'].detach()\n",
    "                biases = params['deform_biases'].detach()\n",
    "\n",
    "            # Calculate the absolute difference between time and biases\n",
    "            time_diff = torch.abs(time - biases)\n",
    "\n",
    "            # Get the indices of the N smallest time differences\n",
    "            _, top_indices = torch.topk(-time_diff, N, dim=1)  # Negative for smallest values\n",
    "\n",
    "            # Create a mask to select only the top N basis functions\n",
    "            mask = torch.zeros_like(time_diff, dtype=torch.float)\n",
    "            mask.scatter_(1, top_indices, 1.0)\n",
    "\n",
    "            # Apply the mask to weights and biases\n",
    "            masked_weights = weights * mask\n",
    "            masked_biases = biases * mask\n",
    "\n",
    "            # Calculate deformations\n",
    "            deform = torch.sum(\n",
    "                masked_weights * torch.exp(-1 / (2 * stds**2) * (time - masked_biases)**2), dim=1\n",
    "            )  # Nx10 gaussians deformations\n",
    "\n",
    "            deform_xyz = deform[:, :3]\n",
    "            deform_rots = deform[:, 3:7]\n",
    "            deform_scales = deform[:, 7:10]\n",
    "        else:\n",
    "            if deform_grad:\n",
    "                weights = params['deform_weights']\n",
    "                stds = params['deform_stds']\n",
    "                biases = params['deform_biases']\n",
    "            else:\n",
    "                weights = params['deform_weights'].detach()\n",
    "                stds = params['deform_stds'].detach()\n",
    "                biases = params['deform_biases'].detach()\n",
    "\n",
    "            # Calculate the absolute difference between time and biases\n",
    "            time_diff = torch.abs(time - biases)\n",
    "\n",
    "            # Get the indices of the N smallest time differences\n",
    "            _, top_indices = torch.topk(-time_diff, N, dim=1)  # Negative for smallest values\n",
    "\n",
    "            # Create a mask to select only the top N basis functions\n",
    "            mask = torch.zeros_like(time_diff, dtype=torch.float)\n",
    "            mask.scatter_(1, top_indices, 1.0).detach()\n",
    "\n",
    "            # Register a gradient hook to zero out gradients for irrelevant basis functions\n",
    "            if deform_grad:\n",
    "                def zero_out_irrelevant_gradients(grad):\n",
    "                    return grad * mask\n",
    "\n",
    "                weights.register_hook(zero_out_irrelevant_gradients)\n",
    "                biases.register_hook(zero_out_irrelevant_gradients)\n",
    "                stds.register_hook(zero_out_irrelevant_gradients)\n",
    "\n",
    "            # Calculate deformations\n",
    "            deform = torch.sum(\n",
    "                weights * torch.exp(-1 / (2 * stds**2) * (time - biases)**2), dim=1\n",
    "            )  # Nx10 gaussians deformations\n",
    "\n",
    "            deform_xyz = deform[:, :3]\n",
    "            deform_rots = deform[:, 3:7]\n",
    "            deform_scales = deform[:, 7:10]\n",
    "\n",
    "        xyz = params['means3D'] + deform_xyz\n",
    "        rots = params['unnorm_rotations'] + deform_rots\n",
    "        scales = params['log_scales'] + deform_scales\n",
    "        opacities = params['logit_opacities']\n",
    "        colors = params['rgb_colors']\n",
    "\n",
    "\n",
    "    elif deformation_type == 'simple':\n",
    "        # with torch.no_grad():\n",
    "        xyz = params['means3D'][time]\n",
    "        rots = params['unnorm_rotations'][time]\n",
    "        scales = params['log_scales'][time]\n",
    "        opacities = params['logit_opacities'][time]\n",
    "        colors = params['rgb_colors'][time]\n",
    "\n",
    "    return xyz, rots, scales,opacities, colors\n",
    "for i in range(params['cam_trans'].shape[-1]):\n",
    "    params['cam_trans'][...,i][...,-1] += 1\n",
    "\n",
    "for id in range(params['cam_unnorm_rots'].shape[-1]):\n",
    "    local_means,local_rots,local_scales,local_opacities,local_colors = deform_gaussians(params,id,deform_grad = True,deformation_type='simple')\n",
    "\n",
    "\n",
    "    #  print(torch.sum(local_means-params['means3D']))\n",
    "\n",
    "    transformed_pts = transform_to_frame(local_means,params,id,False,False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize Render Variables\n",
    "    rendervar = transformed_GRNparams2rendervar(params, transformed_pts,local_rots,local_scales,local_opacities,local_colors)\n",
    "    print(local_scales.max())\n",
    "    rv_store = {}\n",
    "    for key in rendervar.keys():\n",
    "        rv_store[key] = rendervar[key].cpu().detach()\n",
    "        local_means_store = local_means.cpu()\n",
    "        local_scales_store = local_rots.cpu()\n",
    "        local_rots_store = local_rots.cpu()\n",
    "        transformed_pts_store = transformed_pts.cpu()\n",
    "\n",
    "\n",
    "\n",
    "    #  rendervar['means3D'].retain_grad()\n",
    "\n",
    "    depth_sil_rendervar = transformed_GRNparams2depthplussilhouette(params, w2c,\n",
    "                                            transformed_pts,local_rots,local_scales,local_opacities)\n",
    "\n",
    "\n",
    "    #RGB Rendering\n",
    "\n",
    "    rendervar['means2D'].retain_grad()\n",
    "    im, radius, _ = Renderer(raster_settings=cam)(**rendervar)\n",
    "    # variables['means2D'] = rendervar['means2D'] # Gradient only accum from colour render for densification\n",
    "    img = Image.fromarray((im.permute(1,2,0).cpu().detach().numpy()*255).astype(np.uint8))\n",
    "    os.makedirs(f'./eval_plots/plots_simple/',exist_ok=True)\n",
    "    img.save(f'./eval_plots/plots_simple/{id}.png')\n",
    "\n",
    "    print(local_means.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 409])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['cam_trans'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# weights =   params['deform_weights'].cpu().detach()\n",
    "# biases =    params['deform_biases'].cpu().detach()\n",
    "# stds =      params['deform_stds'].cpu().detach()\n",
    "\n",
    "# deforms = []\n",
    "# deformsx1 = []\n",
    "# for time in range(100):\n",
    "#     deform = torch.sum(weights*torch.exp(-1/(2*stds**2)*(time-biases)**2),1)\n",
    "#     deforms.append(deform) # Nx10 gaussians deformations\n",
    "#     deformsx1.append(deform[0,0])\n",
    "# fig,ax = plt.subplots(10,10,figsize = (25,25),sharey=True)\n",
    "# for i in range(10):\n",
    "#     for ii in range(10):\n",
    "#         ax[ii,i].plot([deforms[idx][i+91720//3,ii] for idx in range(len(deforms))])\n",
    "#         ax[ii,i].axhline(y = 0.0,color = 'r', linestyle = '--')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GRN.models.conv_unet import GaussianRegressionNetwork\n",
    "# import torch\n",
    "\n",
    "# state_dict = torch.load('logs/GRN_6/checkpoint.pth',weights_only=False)\n",
    "# model_state_dict = state_dict['model']\n",
    "\n",
    "# model = GaussianRegressionNetwork()\n",
    "# # model.load_state_dict(model_state_dict)\n",
    "\n",
    "# torch.save(model.state_dict(),'GRN/models/GRN_v1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# depth = np.load('/media/thesis_ssd/data/Endonerf/cutting_tissues_twice-20241203T074853Z-001/cutting_tissues_twice/depth/depth_frame-000000.npz')\n",
    "# depth = depth['data']\n",
    "# plt.imshow(depth)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# image_paths = os.listdir('/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/data/RARP/frames/')\n",
    "# # image_paths = image_paths[:2]\n",
    "# for image_path in image_paths:\n",
    "#     image = cv2.imread(os.path.join('/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/data/RARP/frames/', image_path))\n",
    "#     # Convert to grayscale\n",
    "#     image_cropped = image[75:-75, 300:-300]\n",
    "\n",
    "#     cv2.imwrite(os.path.join('/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/data/RARP/frames', f'cropped_{image_path}'), image_cropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cutting_SurgeDepth'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[0].replace('EndoNerf ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experiments/EndoNerf cutting_SurgeDepth/cutting_SurgeDepth',\n",
       " 'experiments/EndoNerf cutting_SurgeDepth_GRN/cutting_SurgeDepth_GRN',\n",
       " 'experiments/EndoNerf cutting_SurgeDepth_GRN_10_percent/cutting_SurgeDepth_GRN_10_percent',\n",
       " 'experiments/Stereomis_2/Stereomis_2',\n",
       " 'experiments/EndoNerf cutting_SurgeDepth_random_init/cutting_SurgeDepth_random_init',\n",
       " 'experiments/EndoNerf cutting_baseline/cutting_baseline',\n",
       " 'experiments/EndoNerf pulling_SurgeDepth_GRN/pulling_SurgeDepth_GRN',\n",
       " 'experiments/SCARED_LONG_seq_2/SCARED_LONG_seq_2',\n",
       " 'experiments/Stereomis_3/Stereomis_3',\n",
       " 'experiments/EndoNerf pulling_SurgeDepth_random_init/pulling_SurgeDepth_random_init',\n",
       " 'experiments/EndoNerf pulling_SurgeDepth_GRN_10_percent/pulling_SurgeDepth_GRN_10_percent',\n",
       " 'experiments/EndoNerf cutting_SurgeDepth_base_10_percent/cutting_SurgeDepth_base_10_percent',\n",
       " 'experiments/EndoNerf pulling_baseline/pulling_baseline',\n",
       " 'experiments/2/2',\n",
       " 'experiments/EndoNerf pulling_deform_simple_54_no_GRN_no_bloat/pulling_deform_simple_54_no_GRN_no_bloat',\n",
       " 'experiments/EndoNerf cutting_SurgeDepth_base_01_percent/cutting_SurgeDepth_base_01_percent',\n",
       " 'experiments/Stereomis_1/Stereomis_1',\n",
       " 'experiments/Snellius_Exps/Snellius_Exps',\n",
       " 'experiments/Stereomis_5/Stereomis_5',\n",
       " 'experiments/EndoNerf pulling_deform_simple_53_no_GRN_bloated/pulling_deform_simple_53_no_GRN_bloated',\n",
       " 'experiments/Stereomis_4/Stereomis_4',\n",
       " 'experiments/EndoNerf pulling_deform_simple_53_no_GRN/pulling_deform_simple_53_no_GRN',\n",
       " 'experiments/EndoNerf pulling_SurgeDepth_base_01_percent/pulling_SurgeDepth_base_01_percent',\n",
       " 'experiments/EndoNerf cutting_SurgeDepth_GRN_01_percent/cutting_SurgeDepth_GRN_01_percent',\n",
       " 'experiments/EndoNerf pulling_SurgeDepth/pulling_SurgeDepth',\n",
       " 'experiments/SCARED_LONG/SCARED_LONG',\n",
       " 'experiments/SCARED_LONG_seq_2_high_deform_penalty/SCARED_LONG_seq_2_high_deform_penalty',\n",
       " 'experiments/EndoNerf cutting_deform_simple_25_best/cutting_deform_simple_25_best',\n",
       " 'experiments/EndoNerf pulling_SurgeDepth_GRN_01_percent/pulling_SurgeDepth_GRN_01_percent',\n",
       " 'experiments/EndoNerf pulling_SurgeDepth_base_10_percent/pulling_SurgeDepth_base_10_percent']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "image_paths = os.listdir('experiments')\n",
    "image_paths = [os.path.join('experiments',image_path,image_path.replace(\"EndoNerf \", '')) for image_path in image_paths]\n",
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experiments/SCARED_LONG_seq_2/SCARED_LONG_seq_2',\n",
       " 'experiments/2/2',\n",
       " 'experiments/EndoNerf pulling_SurgeDepth/pulling_SurgeDepth',\n",
       " 'experiments/SCARED_LONG/SCARED_LONG']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done = [ 'experiments/EndoNerf pulling_SurgeDepth_base_01_percent/pulling_SurgeDepth_base_01_percent','experiments/EndoNerf pulling_SurgeDepth_GRN_01_percent/pulling_SurgeDepth_GRN_01_percent','experiments/EndoNerf pulling_SurgeDepth_base_10_percent/pulling_SurgeDepth_base_10_percent','experiments/EndoNerf pulling_SurgeDepth_GRN_10_percent/pulling_SurgeDepth_GRN_10_percent','experiments/EndoNerf pulling_SurgeDepth_GRN/pulling_SurgeDepth_GRN','experiments/EndoNerf pulling_SurgeDepth_random_init/pulling_SurgeDepth_random_init','experiments/EndoNerf pulling_baseline/pulling_baseline','experiments/EndoNerf pulling_SurgeDepth_random_init/pulling_SurgeDepth_random_init', 'experiments/EndoNerf cutting_SurgeDepth_base_01_percent/cutting_SurgeDepth_base_01_percent', 'experiments/EndoNerf cutting_SurgeDepth_GRN_01_percent/cutting_SurgeDepth_GRN_01_percent','experiments/EndoNerf cutting_SurgeDepth_base_10_percent/cutting_SurgeDepth_base_10_percent','experiments/EndoNerf cutting_SurgeDepth_GRN_10_percent/cutting_SurgeDepth_GRN_10_percent','experiments/EndoNerf cutting_SurgeDepth/cutting_SurgeDepth','experiments/EndoNerf cutting_SurgeDepth_GRN/cutting_SurgeDepth_GRN','experiments/EndoNerf cutting_SurgeDepth_random_init/cutting_SurgeDepth_random_init','experiments/EndoNerf cutting_baseline/cutting_baseline']\n",
    "todo = [image_path for image_path in image_paths if image_path not in done ]\n",
    "todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR , SSIM , LPIPS&FPS&#Gaussians,len_dataset\n",
      "23.0169  &  0.8313  &  0.1752 & 1.7926& 94508 & 124\n",
      "depth metrics: abs_rel & sq_rel & RMSE & RMSE_log & $\\delta_1$& $\\delta_2$& $\\delta_2$& PSNR \n",
      "&     0.1052  &     0.7811  &     8.0465  &     nan  &     0.8738  &     0.9775  &     0.9956  &     29.9083  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "i=5\n",
    "experiment =   f'/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/experiments/Snellius_Exps/Stereomis_9_no_color_change_EndoDAC/Seq_9'\n",
    "lpips_path = os.path.join(experiment, 'eval', 'lpips.txt')\n",
    "psnr_path = os.path.join(experiment, 'eval', 'psnr.txt')\n",
    "# rmse_path = os.path.join(experiment, 'eval', 'rmse.txt')\n",
    "ssim_path = os.path.join(experiment, 'eval', 'ssim.txt')\n",
    "nr_gauss_path = os.path.join(experiment, 'eval','nr_gaussians.txt')\n",
    "depth_metrics_path = os.path.join(experiment,'eval','depth_errors.txt')\n",
    "runtime_path = os.path.join(experiment, 'runtimes.txt')\n",
    "lpips_scores = np.loadtxt(lpips_path)\n",
    "psnr_scores = np.loadtxt(psnr_path)\n",
    "ssim_scores = np.loadtxt(ssim_path)\n",
    "nr_gaussians = np.loadtxt(nr_gauss_path)\n",
    "depth_metrics = np.loadtxt(depth_metrics_path,delimiter=',')\n",
    "len_dataset = len(nr_gaussians)\n",
    "f = open(runtime_path, 'r')\n",
    "# print(f'FPS: {1/float(f.read()[-22:-2])}')\n",
    "fps = 1/float(f.read()[-21:-2])\n",
    "f.close()\n",
    "\n",
    "print(\"PSNR , SSIM , LPIPS&FPS&#Gaussians,len_dataset\")\n",
    "print(\"{:.4f}  &  {:.4f}  &  {:.4f} & {:.4f}& {:.0f} & {:.0f}\".format(psnr_scores.mean(),ssim_scores.mean(),lpips_scores.mean(),fps,nr_gaussians.mean(),len_dataset))\n",
    "# loaded_metrics = np.loadtxt('/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/experiments/EndoNerf cutting_deform_simple_12_baseline_w_surgedepth_w_GRN_w_reduce_gaussians/cutting_deform_simple_12_baseline_w_surgedepth_w_GRN_w_reduce_gaussians/eval/lpips.txt')\n",
    "# loaded_metrics\n",
    "# lpips_scores.mean()\n",
    "print('depth metrics: abs_rel & sq_rel & RMSE & RMSE_log & $\\delta_1$& $\\delta_2$& $\\delta_2$& PSNR ')\n",
    "print((8*\"&     {:.4f}  \").format(*depth_metrics.mean(axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0142   &   0.0286   &  0.8853   \n"
     ]
    }
   ],
   "source": [
    "# depth metrics: abs_rel & sq_rel & RMSE & RMSE_log & $\\delta_1$& $\\delta_2$& $\\delta_2$& PSNR, SSIM \n",
    "# &     0.2439  &     4.6735  &     11.6724  &     0.2780  &     0.5342  &     0.9593  &     0.9806  &     20.7574 & 151\n",
    "# &     0.2390  &     2.7043  &     9.0106  &     0.2798  &     0.5153  &     0.8947  &     0.9928  &     31.0911  & 63\n",
    "\n",
    "# &     0.0118  &     0.0152  &     0.5699  &     0.0313  &     0.9971  &     0.9992  &     0.9997  &     33.9990  \n",
    "# &     0.0201  &     0.0606  &     1.6411  &     0.0631  &     0.9936  &     0.9978  &     0.9991  &     39.0610  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "abs_rel =  (0.0118  * 151 +\n",
    "            0.0201* 63)/(151+63)\n",
    "sq_rel = (  0.0152 * 151 +\n",
    "            0.0606* 63)/(151+63)\n",
    "RMSE = (0.5699 * 151 +\n",
    "        1.6411* 63)/(151+63)\n",
    "\n",
    "print(\"{:.4f}   &   {:.4f}   &  {:.4f}   \".format(abs_rel,sq_rel,RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR , SSIM , LPIPS&FPS\n",
      "24.4745  &  0.8418  &  0.1892 & 1.7506\n"
     ]
    }
   ],
   "source": [
    "# 34.5906  &  0.9763  &  0.0191 & 1.8846& 144967 & 112\n",
    "# 30.3562  &  0.9621  &  0.0585 & 1.7286& 142031 & 125\n",
    "# 36.6161  &  0.9846  &  0.0218 & 1.8244& 129884 & 125\n",
    "# 23.7587  &  0.8347  &  0.1801 & 1.8891& 146993 & 124\n",
    "# 34.3210  &  0.9782  &  0.0289 & 1.9045& 139041 & 124\n",
    "\n",
    "\n",
    "# 31.9759  &  0.9491  &  0.0471 & 2.1415& 21771 & 112\n",
    "# 29.3522  &  0.9547  &  0.0802 & 2.1010& 29990 & 125\n",
    "# 35.3592  &  0.9795  &  0.0391 & 2.1527& 18906 & 125\n",
    "# 21.0869  &  0.7115  &  0.2731 & 2.1466& 29798 & 124\n",
    "# 32.4124  &  0.9671  &  0.0508 & 2.1300& 21407 & 124\n",
    "\n",
    "# 37.0759  &  0.9920  &  0.0518 & 1.6436& 98595 & 19\n",
    "# 34.6432  &  0.9792  &  0.0573 & 1.6617& 100540 & 7\n",
    "\n",
    "\n",
    "# 27.6135  &  0.9175  &  0.1202 & 1.7154& 106572 & 112\n",
    "# 21.9660  &  0.7679  &  0.2584 & 1.8153& 129227 & 125\n",
    "# 29.7295  &  0.9416  &  0.0896 & 1.7559& 109618 & 125\n",
    "# 20.3283  &  0.7580  &  0.2962 & 1.6698& 169451 & 124\n",
    "# 23.0169  &  0.8313  &  0.1752 & 1.7926& 94508  & 124\n",
    "\n",
    "\n",
    "\n",
    "PSNR = (        27.6135 * 112 + \n",
    "                21.9660 * 125 +\n",
    "                29.7295 * 125 +\n",
    "                20.3283 * 124 +\n",
    "                23.0169 * 124 ) / (112+125+125+124+124)\n",
    "SSIM = (        0.9175 * 112 + \n",
    "                0.7679 * 125 +\n",
    "                0.9416 * 125 +\n",
    "                0.7580 * 124 +\n",
    "                0.8313 * 124 ) / (112+125+125+124+124)\n",
    "LPIPS = (        0.1202* 112 + \n",
    "                0.2584* 125 +\n",
    "                0.0896 * 125 +\n",
    "                0.2962 * 124 +\n",
    "                0.1752 * 124 ) / (112+125+125+124+124)\n",
    "FPS = (        1.7154 * 112 + \n",
    "                1.8153 * 125 +\n",
    "                1.7559 * 125 +\n",
    "                1.6698 * 124 +\n",
    "                1.7926 * 124 ) / (112+125+125+124+124)\n",
    "\n",
    "print(\"PSNR , SSIM , LPIPS&FPS\")\n",
    "print(\"{:.4f}  &  {:.4f}  &  {:.4f} & {:.4f}\".format(PSNR,SSIM,LPIPS,FPS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# base_path = '/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/data/SCARED_LONG/StereoMis/color'\n",
    "\n",
    "# for path in os.listdir(base_path):\n",
    "#     img = cv2.imread(os.path.join(base_path,path))\n",
    "#     img_height = img.shape[0]\n",
    "#     cropped_height = img_height//2\n",
    "#     img_resized = img[:cropped_height,:]\n",
    "#     cv2.imwrite(os.path.join(base_path,path),img_resized)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.63  & 0.96& 0.06 & 2.98&18120\n"
     ]
    }
   ],
   "source": [
    "## no GRN,w/ Depth,rand init),100\\%Gauss , 35.6458  ,  0.9789  ,  0.0673 , 1.5157, 115113 , 37.3969  ,  0.9912  ,  0.0338 , 1.6883, 117827\\\\\n",
    "## no GRN,no Depth),100\\%Gauss           , 33.1386  ,  0.9651  ,  0.0742 , 2.8108, 90645  , 36.2283  ,  0.9885  ,  0.0251 , 2.7306, 94526 \\\\\n",
    "## no GRN, w/SD),100\\%Gauss              , 35.6458  ,  0.9789  ,  0.0673 , 1.5157, 115113 , 38.8557  ,  0.9940  ,  0.0103 , 2.2322, 143256\\\\\n",
    "## w/ GRN, w/SD),100\\%Gauss              , 36.7405  ,  0.9820  ,  0.0355 , 2.0480, 108967 , 38.5460  ,  0.9931  ,  0.0162 , 2.1136, 114047\\\\\n",
    "## w/ GRN, w/SD),10\\%Gauss               , 36.1126  ,  0.9791  ,  0.0519 , 2.7710, 11813  , 37.6966  ,  0.9914  ,  0.0253 , 2.8073, 13753\\\\\n",
    "## w/o GRN, w/SD),10\\%Gauss              , 36.7637  ,  0.9833  ,  0.0317 , 2.6277, 41089  , 38.4466  ,  0.9931  ,  0.0130 , 2.6205, 48485\\\\\n",
    "## w/ GRN, w/SD),1\\%Gauss                , 34.2906  ,  0.9671  ,  0.1181 , 3.1629, 1894   , 34.7402  ,  0.9803  ,  0.1036 , 3.1959, 3017\\\\\n",
    "## w/o GRN, w/SD),1\\%Gauss               , 33.1964  ,  0.9349  ,  0.1038 , 3.0525, 13872  , 36.6134  ,  0.9732  ,  0.0462 , 2.9512, 19836\\\\\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([33.1964  ,  0.9349  ,  0.1038 , 3.0525, 13872])*63\n",
    "b = np.array([36.6134  ,  0.9732  ,  0.0462 , 2.9512, 19836])*156\n",
    "# c = np.array([28.0204  ,  0.9190  ,  0.0710])*401\n",
    "# d = np.array([30.8538  ,  0.9620  ,  0.0588])*326\n",
    "\n",
    "\n",
    "avg = (a+b)/(63+156)\n",
    "print('{:.2f}  & {:.2f}& {:.2f} & {:.2f}&{:.0f}'.format(avg[0],avg[1],avg[2],avg[3],avg[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1634   &   1.2918   &  5.5175   \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cutting = np.loadtxt(\"/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/experiments/Snellius_Exps/EndoNerf cutting_SurgeDepth_GRN_EndoDAC/cutting_SurgeDepth_GRN_EndoDAC/eval/depth_errors.txt\",delimiter=',')\n",
    "pulling = np.loadtxt('/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/experiments/Snellius_Exps/EndoNerf pulling_SurgeDepth_GRN_EndoDAC/pulling_SurgeDepth_GRN_EndoDAC/eval/depth_errors.txt',delimiter=',')\n",
    "\n",
    "\n",
    "abs_rel = (pulling[:,0].mean()*len(pulling[:,0])+cutting[:,0].mean()*len(cutting[:,0]))/(pulling.shape[0]+cutting.shape[0])\n",
    "sq_rel = (pulling[:,1].mean()*len(pulling[:,1])+cutting[:,1].mean()*len(cutting[:,1]))/(pulling.shape[0]+cutting.shape[0])\n",
    "RMSE = (pulling[:,2].mean()*len(pulling[:,2])+cutting[:,2].mean()*len(cutting[:,2]))/(pulling.shape[0]+cutting.shape[0])\n",
    "\n",
    "print(\"{:.4f}   &   {:.4f}   &  {:.4f}   \".format(abs_rel,sq_rel,RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pulling.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "endogslam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
